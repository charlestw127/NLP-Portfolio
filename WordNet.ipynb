{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Charles Wallis\n",
        "\n",
        "2/24/2023\n",
        "\n",
        "WordNet is an English list of semantic vocabulary. It classifies words into a synonym group called 'synset', providing a brief and general definition, and records various semantic relationships betweens these vocabulary lists. There are two purposes to wordnet, and one: it is to create a combination of dictionaries (word collections) and sisorus (symmetrical and antonymic dictionaries), which can be used more intuitively, and second: to support automated text analysis and AI applications."
      ],
      "metadata": {
        "id": "pnGZFI4bRxE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTPL3hkLRutl",
        "outputId": "9cebfa33-4cc1-4d34-819e-19b2834ccb81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.book import text4\n",
        "from nltk.wsd import lesk\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('tea') #all synsets of 'charles'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTbyRNH1SvTx",
        "outputId": "91da0386-3fd9-42da-c96c-6f4ba69ca932"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('tea.n.01'),\n",
              " Synset('tea.n.02'),\n",
              " Synset('tea.n.03'),\n",
              " Synset('tea.n.04'),\n",
              " Synset('tea.n.05')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synset('tea.n.01').definition()) #definition\n",
        "print(wn.synset('tea.n.02').definition()) #definition\n",
        "print(wn.synset('tea.n.02').examples()) #usage examples (I like 02 example)\n",
        "print(wn.synset('tea.n.02').lemmas()) #lemmas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR3lU1pFTOsG",
        "outputId": "be26721e-8a06-420e-c02e-02ea7498c93a"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a beverage made by steeping tea leaves in water\n",
            "a light midafternoon meal of tea and sandwiches or cakes\n",
            "['an Englishman would interrupt a war to have his afternoon tea']\n",
            "[Lemma('tea.n.02.tea'), Lemma('tea.n.02.afternoon_tea'), Lemma('tea.n.02.teatime')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Traversing the Hierarchy\n",
        "tea = wn.synset('tea.n.01')\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(tea.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgYuenyjTadf",
        "outputId": "f2cbc483-4a1f-4aa7-8353-71e636b040ac"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('beverage.n.01'),\n",
              " Synset('food.n.01'),\n",
              " Synset('liquid.n.01'),\n",
              " Synset('substance.n.07'),\n",
              " Synset('fluid.n.01'),\n",
              " Synset('matter.n.03'),\n",
              " Synset('substance.n.01'),\n",
              " Synset('physical_entity.n.01'),\n",
              " Synset('part.n.01'),\n",
              " Synset('entity.n.01'),\n",
              " Synset('relation.n.01'),\n",
              " Synset('abstraction.n.06')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the word 'tea', wordnet organized it into a beverage, which is a food, which is a category of liquid, which is a substance, and so on until it reaches abstraction which I thought was interesting, since most other nouns stopped at being an entity."
      ],
      "metadata": {
        "id": "Kst7CyhQun-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synset('tea.n.01').hypernyms())\n",
        "print(wn.synset('tea.n.01').hyponyms())\n",
        "print(wn.synset('tea.n.03').part_meronyms())\n",
        "print(wn.synset('tea.n.05').part_holonyms())\n",
        "print(wn.synset('tea.n.01').lemmas()[0].antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxc0BuvAvD3t",
        "outputId": "25c54993-092f-469b-8d24-9a16c493b1fd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('beverage.n.01')]\n",
            "[Synset('cambric_tea.n.01'), Synset('cuppa.n.01'), Synset('herb_tea.n.01'), Synset('ice_tea.n.01'), Synset('sun_tea.n.01')]\n",
            "[Synset('tea.n.05')]\n",
            "[Synset('tea.n.03')]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "meronyms, holonyms, and antonyms did not exist in the WordNet for 'tea', except for tea.n.03 and tea.n.05 were meronyms and holonyms for each other. There are no antonyms for the word tea, since it's just a beverage."
      ],
      "metadata": {
        "id": "t7eCiF6yv-Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying synsets of the verb drink\n",
        "wn.synsets('drink')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InQLmAkawZ_v",
        "outputId": "4a60e83a-5540-4455-9878-351038919fca"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('drink.n.01'),\n",
              " Synset('drink.n.02'),\n",
              " Synset('beverage.n.01'),\n",
              " Synset('drink.n.04'),\n",
              " Synset('swallow.n.02'),\n",
              " Synset('drink.v.01'),\n",
              " Synset('drink.v.02'),\n",
              " Synset('toast.v.02'),\n",
              " Synset('drink_in.v.01'),\n",
              " Synset('drink.v.05')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synset('drink.n.05').definition()) \n",
        "print(wn.synset('drink.n.05').examples()) \n",
        "print(wn.synset('drink.n.05').lemmas())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6blgJb9wmeP",
        "outputId": "783ac050-24d5-48e5-dc90-9efec32f8d3a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the act of swallowing\n",
            "['one swallow of the liquid was enough', 'he took a drink of his beer and smacked his lips']\n",
            "[Lemma('swallow.n.02.swallow'), Lemma('swallow.n.02.drink'), Lemma('swallow.n.02.deglutition')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, going through drink.n.01 up to 05 reminded me that the word 'drink' is also used as a noun, and 02 and 05 were the only \"verb\" definitions, and the 02 definition was specific to drinking alcoholic beverages. (even the 05 gave a beer example)"
      ],
      "metadata": {
        "id": "lGPc_xwlw1Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Traversing the Hierarchy\n",
        "drinking = wn.synset('drink.n.05')\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(drinking.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgt1EQFoxAIz",
        "outputId": "07cfd6df-5c76-4a56-da24-52c25900a37e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('consumption.n.01'),\n",
              " Synset('bodily_process.n.01'),\n",
              " Synset('organic_process.n.01'),\n",
              " Synset('process.n.06'),\n",
              " Synset('physical_entity.n.01'),\n",
              " Synset('entity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like nouns, it was processing up one broader idea at a time on what the \"drinking\" act is actually doing. A living thing will consume a liquid as a bodily process, which is an organic one, done by a physical entity. Perhaps I used a verb that is also used as a noun, but it seems like there are not significant difference in traversing through a noun hierarchy and a verb hierarchy."
      ],
      "metadata": {
        "id": "rzXB7jPIxwHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.morphy('drink', wn.NOUN))\n",
        "print(wn.morphy('drinks', wn.NOUN))\n",
        "print(wn.morphy('drink', wn.VERB))\n",
        "print(wn.morphy('drank', wn.VERB))\n",
        "print(wn.morphy('drunk', wn.VERB))\n",
        "print(wn.morphy('drinks', wn.VERB))\n",
        "print(wn.morphy('drinked', wn.VERB))\n",
        "print(wn.morphy('drinking', wn.VERB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YANU2jnVyO5A",
        "outputId": "8e002b88-73f9-4006-8042-311b47c1fadf"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drink\n",
            "drink\n",
            "drink\n",
            "drink\n",
            "drink\n",
            "drink\n",
            "drink\n",
            "drink\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting two words that I think are similar and finding synsets\n",
        "print(wn.synsets('tea'))\n",
        "print(wn.synsets('wine'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTjkTqiTz1d3",
        "outputId": "24865ccc-605c-4847-9753-e08f1fc2ab9e"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('tea.n.01'), Synset('tea.n.02'), Synset('tea.n.03'), Synset('tea.n.04'), Synset('tea.n.05')]\n",
            "[Synset('wine.n.01'), Synset('wine.n.02'), Synset('wine.v.01'), Synset('wine.v.02')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in wn.synsets(str('wine')):\n",
        "  print(n, n.definition())\n",
        "#I will be using wine.n.01, and tea.n.01 (from above)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3KqfYdR0EFp",
        "outputId": "b7467c82-a133-46f1-a34a-699f1647807d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('wine.n.01') fermented juice (of grapes especially)\n",
            "Synset('wine.n.02') a red as dark as red wine\n",
            "Synset('wine.v.01') drink wine\n",
            "Synset('wine.v.02') treat to wine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Wu-Palmer Similarity: \", wn.wup_similarity(wn.synset('wine.n.01'), wn.synset('tea.n.01')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv71U95a0phA",
        "outputId": "980d28cf-cc7f-4866-a9b3-20c0251a9bae"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wu-Palmer Similarity:  0.8421052631578947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out the Lesk algorithm"
      ],
      "metadata": {
        "id": "MYMJVk9W2Dux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display all of the term definitions\n",
        "for n in wn.synsets(str('tea')):\n",
        "  print(n, n.definition())\n",
        "\n",
        "print()\n",
        "\n",
        "for n in wn.synsets(str('wine')):\n",
        "  print(n, n.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XWNaUlr1kqH",
        "outputId": "29e18a28-eb1d-4cd3-98de-902b0238efc1"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('tea.n.01') a beverage made by steeping tea leaves in water\n",
            "Synset('tea.n.02') a light midafternoon meal of tea and sandwiches or cakes\n",
            "Synset('tea.n.03') a tropical evergreen shrub or small tree extensively cultivated in e.g. China and Japan and India; source of tea leaves\n",
            "Synset('tea.n.04') a reception or party at which tea is served\n",
            "Synset('tea.n.05') dried leaves of the tea shrub; used to make tea\n",
            "\n",
            "Synset('wine.n.01') fermented juice (of grapes especially)\n",
            "Synset('wine.n.02') a red as dark as red wine\n",
            "Synset('wine.v.01') drink wine\n",
            "Synset('wine.v.02') treat to wine\n",
            "['Our relatives in Italy wined and dined us for a week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#writing sample sentences for lesk\n",
        "sentence1 = ['The', 'tea', 'is', 'too', 'hot', 'to', 'drink']\n",
        "sentence2 = ['black', 'tea', 'with', 'some', 'sugar', 'goes', 'well', 'with', 'a', 'strawberry', 'shortcake']\n",
        "sentence3 = ['I', 'planted', 'a', 'tea', 'tree', 'to', 'harvest', 'some', 'oil', 'from', 'it']\n",
        "sentence4 = ['I', 'am', 'going', 'to', 'a', 'tea', 'party', 'with', 'my', 'friends']\n",
        "sentence5 = ['I', 'packaged', 'the', 'dried', 'tea', 'leaves', 'so', 'I', 'can', 'brew', 'it', 'later']\n",
        "\n",
        "sentence6 = ['Would', 'you', 'like', 'a', 'glass', 'of', 'wine?']\n",
        "sentence7 = ['my', 'favorite', 'color', 'is', 'wine']\n",
        "sentence8 = ['I', 'would', 'like', 'to', 'get', 'some', 'wine', 'with', 'my', 'meal']\n",
        "sentence9 = ['Would', 'you', 'like', 'to', 'wine', 'and', 'dine', 'with' ,'me?']"
      ],
      "metadata": {
        "id": "ubV12Zij3L3N"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running the lesk algorithm to check if it detects with correct noun for each different uses of noun\n",
        "print(lesk(sentence1, 'tea')) #I'll count that as a correct\n",
        "print(lesk(sentence2, 'tea')) #wrong\n",
        "print(lesk(sentence3, 'tea')) #correct\n",
        "print(lesk(sentence4, 'tea')) #correct\n",
        "print(lesk(sentence5, 'tea')) #correct\n",
        "\n",
        "print(lesk(sentence6, 'wine')) #wrong\n",
        "print(lesk(sentence7, 'wine')) #wrong\n",
        "print(lesk(sentence8, 'wine')) #wrong\n",
        "print(lesk(sentence9, 'wine')) #correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vWdW3Zs65Do",
        "outputId": "cc80d2db-cc75-4916-b18c-b4b8aa90b74f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('tea.n.05')\n",
            "Synset('tea.n.04')\n",
            "Synset('tea.n.03')\n",
            "Synset('tea.n.04')\n",
            "Synset('tea.n.05')\n",
            "Synset('wine.n.02')\n",
            "Synset('wine.v.02')\n",
            "Synset('wine.v.02')\n",
            "Synset('wine.v.02')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the Wu-Palmer algorithm seems to capture the similarity between words very well, since it gave a pretty high number for something I did expect to have a high similarity. \n",
        "\n",
        "The lesk algorithm worked surprisingly well for the tea example, even when the definitions confused me when I wrote the sentences. surprisingly the wine words didn't work as intended, even when I thought I got those down (like sentence 7, where I used it as a color). "
      ],
      "metadata": {
        "id": "wOJQ55517WJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet\n",
        "\n",
        "SentiWordNet uses WordNet's resources to attach sentience attributes to words and sentences. Each synset has 3 sentiment scores (positive, negative, and objectivity), where the sum of all three is 1. This is applicable in sentiment analysis, trying to read the tone of a sentence, identify tone of a product review, or detect toxic behaviors in an online game"
      ],
      "metadata": {
        "id": "Jaxugw4L-ydk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Scores for the word \\'Like\\'')\n",
        "print('Positive: ', swn.senti_synset('like.v.02').pos_score())\n",
        "print('Negative: ', swn.senti_synset('like.v.02').neg_score())\n",
        "print('Objective: ', swn.senti_synset('like.v.02').obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_TKWiNhGVBC",
        "outputId": "5acb8e91-3d99-4a90-c8bb-06b98e424be6"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores for the word 'Like'\n",
            "positive:  1.0\n",
            "negative:  0.0\n",
            "objective:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Scores for the word \\'Fear\\'')\n",
        "print('Positive: ', swn.senti_synset('fear.v.01').pos_score())\n",
        "print('Negative: ', swn.senti_synset('fear.v.01').neg_score())\n",
        "print('Objective: ', swn.senti_synset('fear.v.01').obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vRHjJh1Kh1K",
        "outputId": "3cbbb3b8-17c0-4a11-b3f6-88e5b304a3d4"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores for the word 'Fear'\n",
            "Positive:  0.125\n",
            "Negative:  0.625\n",
            "Objective:  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet in Sentences"
      ],
      "metadata": {
        "id": "y6wpDCs0LUN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#writing sample sentences for SentiWordNet\n",
        "sentiSentence1 = 'I enjoy drinking warm tea to calm myself down'\n",
        "sentiSentence2 = 'My teammate is being so unhelpful'"
      ],
      "metadata": {
        "id": "76lrMQetLS_W"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wordsInSentencePolarity(phrase):\n",
        "  word = phrase.split()\n",
        "  print(phrase) \n",
        "  for w in word:\n",
        "      synsets = list(swn.senti_synsets(w))     \n",
        "      if synsets: #if synsets exist for the word, choose the first one\n",
        "          print(w)\n",
        "          print(\"Positive : \", synsets[0].pos_score())\n",
        "          print(\"Negative : \", synsets[0].neg_score())\n",
        "          print(\"Objective: \", synsets[0].obj_score(), '\\n')"
      ],
      "metadata": {
        "id": "XEvNYqSZMMfo"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output the polarity for each word in the first sentence\n",
        "wordsInSentencePolarity(sentiSentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR0jHHeNS64s",
        "outputId": "b78be1cd-d1d4-422b-ae31-6cd9223cdddc"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I enjoy drinking warm tea to calm myself down\n",
            "I\n",
            "Positive :  0.0\n",
            "Negative :  0.0\n",
            "Objective:  1.0 \n",
            "\n",
            "enjoy\n",
            "Positive :  0.375\n",
            "Negative :  0.0\n",
            "Objective:  0.625 \n",
            "\n",
            "drinking\n",
            "Positive :  0.0\n",
            "Negative :  0.0\n",
            "Objective:  1.0 \n",
            "\n",
            "warm\n",
            "Positive :  0.25\n",
            "Negative :  0.0\n",
            "Objective:  0.75 \n",
            "\n",
            "tea\n",
            "Positive :  0.0\n",
            "Negative :  0.0\n",
            "Objective:  1.0 \n",
            "\n",
            "calm\n",
            "Positive :  0.375\n",
            "Negative :  0.0\n",
            "Objective:  0.625 \n",
            "\n",
            "down\n",
            "Positive :  0.125\n",
            "Negative :  0.0\n",
            "Objective:  0.875 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first sentence, \"I enjoy drinking warm tea to calm myself down\" gave mostly objective, but positive polarity scores and no negative polarity scores in the words. An application I can think of would be that I would get an average score for each to determine the polarity of a sentence. "
      ],
      "metadata": {
        "id": "flI_2OsdTTrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Output the polarity for each word in the second sentence\n",
        "wordsInSentencePolarity(sentiSentence2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M11rkhM8TDny",
        "outputId": "7d216eb3-f775-434c-fa9e-d5a7920e67fd"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My teammate is being so unhelpful\n",
            "teammate\n",
            "Positive :  0.0\n",
            "Negative :  0.0\n",
            "Objective:  1.0 \n",
            "\n",
            "is\n",
            "Positive :  0.25\n",
            "Negative :  0.125\n",
            "Objective:  0.625 \n",
            "\n",
            "being\n",
            "Positive :  0.0\n",
            "Negative :  0.0\n",
            "Objective:  1.0 \n",
            "\n",
            "so\n",
            "Positive :  0.0\n",
            "Negative :  0.0\n",
            "Objective:  1.0 \n",
            "\n",
            "unhelpful\n",
            "Positive :  0.125\n",
            "Negative :  0.25\n",
            "Objective:  0.625 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second sentence, \"My teammate is being so unhelpful\n",
        "\" was intended to be a negative sentence, but the positive polarity sums up to 0.375 and negative polarity also sums up to 0.375, which makes this sentence not particularly positive or negative, but rather objective.\n",
        "\n",
        "Which makes me think, maybe this sentence isn't necessarily negative. SentiWordNet is pretty accurate in word polarity, but I think there is a gap between how computers understand these sentences from humans because we are also able to read context and infer that the speaker of this sentence would be upset about the situation. \n",
        "\n",
        "In NLP, this techniques can definitely be used in detecting and capturing different sentiences online when a mass-processing is needed. I would trust this to label sentences correctly so I don't have to read through everything and label them myself."
      ],
      "metadata": {
        "id": "HZfTkr4cTwki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocation\n",
        "\n",
        "Collocations are words that are put together to mean something else. 'pay attention' is a common word, where both words mean something completely different from when they are put together."
      ],
      "metadata": {
        "id": "zDOxvpAAVNuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text4.collocations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRaj1ukZV6np",
        "outputId": "f1bb16f7-ce35-4260-a288-c7f96bb8edca"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I will choose 'United States' as a collocation to calculate mutual information\n",
        "text4words = ' '.join(text4.tokens)\n",
        "d = len(set(text4))\n",
        "\n",
        "#set the P info / how often is this word shown in text4\n",
        "US = text4words.count('United States')/d\n",
        "U = text4words.count('United')/d\n",
        "S = text4words.count('States')/d\n",
        "\n",
        "#mutual information = log( P(x,y) / (P(x)*P(y)) )\n",
        "MI = math.log2(US/(U*S))\n",
        "\n",
        "#display results\n",
        "print(\"P(United States): \", US)\n",
        "print(\"P(United): \", U)\n",
        "print(\"P(States): \", S)\n",
        "print(\"Mutual Information: \", MI)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH1HB7eKWByi",
        "outputId": "be06d348-e829-4c55-f20b-f5e3ab782c2f"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(United States):  0.015860349127182045\n",
            "P(United):  0.0170573566084788\n",
            "P(States):  0.03301745635910224\n",
            "Mutual Information:  4.815657649820885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word United and States both appear pretty often, at 0.01705 and 0.03302 respectively. The probability of \"United States\" appearing is at 0.01586 which is barely below the chance of seeing the word \"United\", at only 7% difference between them. The Mutual Information score is really high due to this, indicating that the word \"United States\" is likely to be a collocation. \n",
        "\n",
        "If the Mutual Information scores are closer to 0, it would mean that the words are less likely of being a collocation, and if the MI score is negative then with high significance we can assume that the word is not a collocation."
      ],
      "metadata": {
        "id": "lnJ2zY9PX4-m"
      }
    }
  ]
}