{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1nqnA5ysHmS",
        "outputId": "36fa81f9-7043-4cf2-c804-4b61c8e8143a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.9/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:20:32.098391Z",
          "start_time": "2022-11-29T11:20:32.080406Z"
        },
        "_cell_guid": "89c8c923-c0bf-7b35-9ab8-e63f00b74e5a",
        "_uuid": "d2bc3bbd2ea3961c49e6673145a0a7226c160e58",
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "oUumBIuQModE"
      },
      "outputs": [],
      "source": [
        "# Charles Wallis\n",
        "# Sentiment Analysis using RNN and Naive Bayes\n",
        "# https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "YX8krFnxuf80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "path_to_zip_file = r'/content/drive/MyDrive/UTD/.UTD 2023 Spring/CS 4395/sentiment labelled sentences.zip'\n",
        "directory_to_extract_to = \"sentiment labelled sentences\"\n",
        "!mkdir \"sentiment labelled sentences\"\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "fileDir = r\"sentiment labelled sentences/sentiment labelled sentences\"\n",
        "fileList = ['imdb_labelled.txt','amazon_cells_labelled.txt', 'yelp_labelled.txt']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUc3yKhUraJt",
        "outputId": "ca39cbae-49c1-4b35-8452-3b241d5d8077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:23:35.175761Z",
          "start_time": "2022-11-29T11:23:35.159761Z"
        },
        "id": "tg0hvIVcModE"
      },
      "outputs": [],
      "source": [
        "dataset = pd.DataFrame()\n",
        "for file in fileList:\n",
        "    dataset = dataset.append(pd.read_csv(os.path.join(fileDir, file), sep='\\t', header=None), ignore_index=True)\n",
        "dataset.columns = ['Phrase','Sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:23:40.943748Z",
          "start_time": "2022-11-29T11:23:40.926743Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llW45rD9ModF",
        "outputId": "5c64c095-8845-43bc-a3e4-2e50fe76791e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1386\n",
              "0    1362\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:23:41.974863Z",
          "start_time": "2022-11-29T11:23:41.950862Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "p_UA0iMQModG",
        "outputId": "34cf3f34-f374-472f-e403-cad5dae28504"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Phrase  Sentiment\n",
              "0     A very, very, very slow-moving, aimless movie ...          0\n",
              "1     Not sure who was more lost - the flat characte...          0\n",
              "2     Attempting artiness with black & white and cle...          0\n",
              "3          Very little music or anything to speak of.            0\n",
              "4     The best scene in the movie was when Gerardo i...          1\n",
              "...                                                 ...        ...\n",
              "2743  I think food should have flavor and texture an...          0\n",
              "2744                           Appetite instantly gone.          0\n",
              "2745  Overall I was not impressed and would not go b...          0\n",
              "2746  The whole experience was underwhelming, and I ...          0\n",
              "2747  Then, as if I hadn't wasted enough of my life ...          0\n",
              "\n",
              "[2748 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8de52bdd-4fce-4ceb-8013-2277584789c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2743</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2744</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2745</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2746</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2747</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2748 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de52bdd-4fce-4ceb-8013-2277584789c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8de52bdd-4fce-4ceb-8013-2277584789c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8de52bdd-4fce-4ceb-8013-2277584789c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:23:43.035198Z",
          "start_time": "2022-11-29T11:23:42.993198Z"
        },
        "id": "v2xBq_9pModG"
      },
      "outputs": [],
      "source": [
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:24:31.017757Z",
          "start_time": "2022-11-29T11:24:31.007758Z"
        },
        "_cell_guid": "c611b55c-92e4-4a33-8e82-1812bef6193d",
        "_uuid": "8b10995b0832ec98ba0c75832186fcb09b1a2d5f",
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Zn8dMz4VModH"
      },
      "outputs": [],
      "source": [
        "#Split to test and train\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size=0.2, random_state=1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment prediction using LSTM "
      ],
      "metadata": {
        "id": "pt0Fyeinujk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set LSTM hyperparams\n",
        "embed_dim = 128 \n",
        "lstm_out = 196\n",
        "max_features = 2000\n",
        "tokenizerLSTM = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizerLSTM.fit_on_texts(dataset['Phrase'].values)\n",
        "X = tokenizerLSTM.texts_to_sequences(dataset['Phrase'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
        "LSTM_model.add(SpatialDropout1D(0.4))\n",
        "LSTM_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "LSTM_model.add(Dense(2,activation='softmax'))\n",
        "LSTM_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(LSTM_model.summary())"
      ],
      "metadata": {
        "id": "AR4k_CGpurEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f538ab-f70e-47fd-ea64-889ab1d86668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1267, 128)         256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 1267, 128)        0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               254800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 394       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(dataset['Sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 1234)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "batch_size = 32\n",
        "LSTM_model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xchElfxZ7cUc",
        "outputId": "cbc082d1-dd9d-493f-b767-288b44b206ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1841, 1267) (1841, 2)\n",
            "(907, 1267) (907, 2)\n",
            "Epoch 1/7\n",
            "58/58 - 471s - loss: 0.6757 - accuracy: 0.5731 - 471s/epoch - 8s/step\n",
            "Epoch 2/7\n",
            "58/58 - 419s - loss: 0.5850 - accuracy: 0.7192 - 419s/epoch - 7s/step\n",
            "Epoch 3/7\n",
            "58/58 - 414s - loss: 0.4562 - accuracy: 0.8213 - 414s/epoch - 7s/step\n",
            "Epoch 4/7\n",
            "58/58 - 410s - loss: 0.3129 - accuracy: 0.8821 - 410s/epoch - 7s/step\n",
            "Epoch 5/7\n",
            "58/58 - 433s - loss: 0.2072 - accuracy: 0.9240 - 433s/epoch - 7s/step\n",
            "Epoch 6/7\n",
            "58/58 - 521s - loss: 0.1438 - accuracy: 0.9538 - 521s/epoch - 9s/step\n",
            "Epoch 7/7\n",
            "58/58 - 443s - loss: 0.1012 - accuracy: 0.9685 - 443s/epoch - 8s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f989e10e100>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 500\n",
        "\n",
        "X_validate = X_test[-test_size:]\n",
        "Y_validate = Y_test[-test_size:]\n",
        "X_test = X_test[:-test_size]\n",
        "Y_test = Y_test[:-test_size]\n",
        "score,acc = LSTM_model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "metadata": {
        "id": "xiiI9BlLFUeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7adae17b-31b9-4dd4-e088-85fe890361cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 - 12s - loss: 0.5279 - accuracy: 0.8059 - 12s/epoch - 958ms/step\n",
            "score: 0.53\n",
            "acc: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_positives, total_negatives, correct_positives, correct_negatives = 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "    result = LSTM_model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 0)[0]\n",
        "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "        if np.argmax(Y_validate[x]) == 0:\n",
        "            correct_negatives += 1\n",
        "        else:\n",
        "            correct_positives += 1\n",
        "    if np.argmax(Y_validate[x]) == 0:\n",
        "        total_negatives += 1\n",
        "    else:\n",
        "        total_positives += 1"
      ],
      "metadata": {
        "id": "_Lc3dngpFgAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"positive sentiment accuracy\", correct_positives/total_positives*100, \"%\")\n",
        "print(\"negative sentiment accuracy\", correct_negatives/total_negatives*100, \"%\")"
      ],
      "metadata": {
        "id": "Dq4lA1LBG4zS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de67f25-eb63-437e-d9ee-7f8f04a76a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive sentiment accuracy 81.27490039840637 %\n",
            "negative sentiment accuracy 76.70682730923694 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment prediction using Naive Bayes"
      ],
      "metadata": {
        "id": "qATFB9RPuY9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T11:24:32.160225Z",
          "start_time": "2022-11-29T11:24:32.151227Z"
        },
        "id": "GsVT99xiModK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567a67f5-67d2-4b2a-dacb-c9efae6bad66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy:  0.8\n"
          ]
        }
      ],
      "source": [
        "#Multinomial Naive\n",
        "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size=0.2, random_state=1234)\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)\n",
        "\n",
        "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
        "print(\"MNB Accuracy: \", accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T13:12:26.037722Z",
          "start_time": "2022-11-29T13:12:25.965716Z"
        },
        "id": "3D5BEuBMModN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2285a0b5-0587-46f2-dd56-d92bd58e4f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy:  0.62\n"
          ]
        }
      ],
      "source": [
        "#MNB But with 2,2 ngram\n",
        "cv = CountVectorizer(stop_words='english', ngram_range = (2,2), tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'],test_size=0.2, random_state=1234)\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)\n",
        "\n",
        "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
        "print(\"MNB Accuracy: \", accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T13:12:35.885679Z",
          "start_time": "2022-11-29T13:12:35.830681Z"
        },
        "id": "jjd4_-fhModP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29cb05c1-2fb7-4981-f094-9991ec74a8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy:  0.5309090909090909\n"
          ]
        }
      ],
      "source": [
        "#MNB But with 3,3 ngram\n",
        "cv = CountVectorizer(stop_words='english', ngram_range = (3,3), tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'],test_size=0.2, random_state=1234)\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)\n",
        "\n",
        "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
        "print(\"MNB Accuracy: \", accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T13:09:01.840960Z",
          "start_time": "2022-11-29T13:09:01.670397Z"
        },
        "id": "b_mLQWoHModS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da21513-3bb4-41a7-9e89-92c3aad6cd01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Gaussian Naive Bayes\n",
        "GNB = GaussianNB()\n",
        "GNB.fit(X_train.todense(), Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T13:09:03.326128Z",
          "start_time": "2022-11-29T13:09:03.311127Z"
        },
        "id": "TkdFCg_iModT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ea6448-a6d0-4129-cad4-544602828d86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#Bernoulli Naive Bayes\n",
        "BNB = BernoulliNB()\n",
        "BNB.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-11-29T13:15:01.150335Z",
          "start_time": "2022-11-29T13:15:00.845992Z"
        },
        "id": "LLu8amx_ModV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c1d874-b789-4b4e-c402-ad9a23301354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy:  0.8418181818181818\n",
            "BNB Accuracy:  0.8036363636363636\n",
            "MNB Accuracy:  0.7127272727272728\n"
          ]
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "text_count_2 = tfidf.fit_transform(dataset['Phrase'])\n",
        "x_train, x_test, y_train, y_test = train_test_split(text_count_2, dataset['Sentiment'],test_size=0.2,random_state=1234)\n",
        "\n",
        "MNB.fit(x_train, y_train)\n",
        "accuracy_score_mnb = metrics.accuracy_score(MNB.predict(x_test), y_test)\n",
        "print(\"MNB Accuracy: \", accuracy_score_mnb)\n",
        "\n",
        "BNB.fit(x_train, y_train)\n",
        "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(x_test), y_test)\n",
        "print(\"BNB Accuracy: \", accuracy_score_bnb)\n",
        "\n",
        "GNB.fit(x_train.todense(), y_train)\n",
        "accuracy_score_gnb = metrics.accuracy_score(GNB.predict(x_test.todense()), y_test)\n",
        "print(\"MNB Accuracy: \", accuracy_score_gnb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the models to my drive as an h5 file (so I don't have to re-train it when I open colab again)\n",
        "import pickle\n",
        "# r\"/content/drive/MyDrive/UTD/.UTD 2022 Fall/CS 4372/'\n",
        "with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/gnb_model.h5\", 'wb') as f:\n",
        "  pickle.dump(GNB, f)\n",
        "with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/bnb_model.h5\", 'wb') as f:\n",
        "  pickle.dump(BNB, f)\n",
        "with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/cnb_model.h5\", 'wb') as f:\n",
        "  pickle.dump(MNB, f)\n",
        "with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/lstm_model.h5\", 'wb') as f:\n",
        "  pickle.dump(LSTM_model, f)\n",
        "if(False): #set to True to load the models\n",
        "  with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/gnb_model.h5\", 'rb') as f:\n",
        "      GNB = pickle.load(f)\n",
        "  with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/bnb_model.h5\", 'rb') as f:\n",
        "      BNB = pickle.load(f)\n",
        "  with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/cnb_model.h5\", 'rb') as f:\n",
        "      MNB = pickle.load(f)\n",
        "  with open(r\"/content/drive/MyDrive/UTD/.UTD 2023 Spring/4395/lstm_model.h5\", 'rb') as f:\n",
        "      LSTM_model = pickle.load(f)"
      ],
      "metadata": {
        "id": "gr2Kmc0ldaeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "kCVt46mPWS5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def miscalulationsNB(model, transformer, dataset, NMiss = 10):\n",
        "  acc = 0\n",
        "  FalsePositive = []\n",
        "  PositiveFalse = []\n",
        "  cnt = len(dataset['Phrase'].values)\n",
        "  for i in range(len(dataset['Phrase'].values)):\n",
        "    phrase = dataset['Phrase'].values[i]  \n",
        "    ans = dataset['Sentiment'].values[i]\n",
        "    try:\n",
        "      pred = model.predict(transformer.transform([phrase]))[0]\n",
        "    except:\n",
        "      pred = model.predict(transformer.transform([phrase]).toarray())[0]\n",
        "    acc += 1 if ans == pred else 0\n",
        "    #print(phrase, ans, pred)\n",
        "    if ans != pred:\n",
        "      #print(phrase, ans, pred)\n",
        "      if( ans == 0):\n",
        "        PositiveFalse.append([phrase, ans, pred])\n",
        "      else:\n",
        "        FalsePositive.append([phrase, ans, pred])\n",
        "    #if(len(PositiveFalse)>=NMiss and len(FalsePositive)>=NMiss):\n",
        "      #break\n",
        "\n",
        "  print( f\"Accuracy: {acc/cnt*100}%\")  \n",
        "  print(f\"{NMiss} Missclassifications of FalsePositives: \")\n",
        "  print(FalsePositive[0:NMiss])\n",
        "  print(f\"{NMiss} Missclassifications of PositiveFalses: \")\n",
        "  print(PositiveFalse[0:NMiss])\n",
        "\n",
        "print(\"=========== MNB Missclassification Examples ========\") \n",
        "miscalulationsNB(MNB, tfidf, dataset)\n",
        "print(\"=========== BNB Missclassification Examples ========\") \n",
        "miscalulationsNB(BNB, tfidf, dataset)  \n",
        "print(\"=========== GNB Missclassification Examples ========\") \n",
        "miscalulationsNB(GNB, tfidf, dataset)  "
      ],
      "metadata": {
        "id": "QusQ6KudQsDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d108db0-46fb-4ab9-9946-fd055192b3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== MNB Missclassification Examples ========\n",
            "Accuracy: 92.97671033478893%\n",
            "10 Missclassifications of FalsePositives: \n",
            "[[\"This if the first movie I've given a 10 to in years.  \", 1, 0], ['If there was ever a movie that needed word-of-mouth to promote, this is it.  ', 1, 0], ['Give this one a look.  ', 1, 0], ['It actually turned out to be pretty decent as far as B-list horror/suspense films go.  ', 1, 0], [\"I don't think you will be disappointed.  \", 1, 0], ['Some applause should be given to the \"prelude\" however.  ', 1, 0], ['The movie had you on the edge of your seat and made you somewhat afraid to go to your car at the end of the night.  ', 1, 0], ['I liked this movie way too much.  ', 1, 0], [\"Still, I do like this movie for it's empowerment of women; there's not enough movies out there like this one.  \", 1, 0], ['You\\'ll love it!  \\t1\\nThis movie is BAD.  \\t0\\nSo bad.  \\t0\\nThe film is way too long.  \\t0\\nThis is definitely one of the bad ones.  \\t0\\nThe movie I received was a great quality film for it\\'s age.  \\t1\\nJohn Wayne did an incredible job for being so young in the movie industry.  \\t1\\nHis on screen presence shined thought even though there were other senior actors on the screen with him.  \\t1\\nI think that it is a must see older John Wayne film.  \\t1\\nI really don\\'t see how anyone could enjoy this movie.  \\t0\\nI don\\'t think I\\'ve ever seen a movie half as boring as this self-indulgent piece of junk.  \\t0\\nIt probably would have been better if the director hadn\\'t spent most of the movie showcasing his own art work, which really isn\\'t that noteworthy.  \\t0\\nAnother thing I didn\\'t really like is when a character got punched in the face, a gallon of blood would spew forth soon after.  \\t0\\nJamie Foxx absolutely IS Ray Charles.  \\t1\\nHis performance is simply genius.  \\t1\\nHe owns the film, just as Spacek owned Coal Miner\\'s Daughter\" and Quaid owned \"Great Balls of Fire.  ', 1, 0]]\n",
            "10 Missclassifications of PositiveFalses: \n",
            "[[\"The directing and the cinematography aren't quite as good.  \", 0, 1], ['All in all, a great disappointment.  ', 0, 1], ['I saw \"Mirrormask\" last night and it was an unsatisfactory experience.  ', 0, 1], ['The fish is badly made and some of its underwater shots are repeated a thousand times in the film.  ', 0, 1], ['This film has no redeeming features.  ', 0, 1], ['Everything is appalling.  ', 0, 1], ['The lead man is charisma-free.  ', 0, 1], ['Highly unrecommended.  ', 0, 1], [\"The guy who said he's had better dialogue with his potted plants has it right.  \", 0, 1], ['I wish I could enter negative values, admins?  ', 0, 1]]\n",
            "=========== BNB Missclassification Examples ========\n",
            "Accuracy: 90.28384279475983%\n",
            "10 Missclassifications of FalsePositives: \n",
            "[['This is a very \"right on case\" movie that delivers everything almost right in your face.  ', 1, 0], [\"This if the first movie I've given a 10 to in years.  \", 1, 0], ['If there was ever a movie that needed word-of-mouth to promote, this is it.  ', 1, 0], ['It actually turned out to be pretty decent as far as B-list horror/suspense films go.  ', 1, 0], [\"I don't think you will be disappointed.  \", 1, 0], ['Some applause should be given to the \"prelude\" however.  ', 1, 0], ['The movie had you on the edge of your seat and made you somewhat afraid to go to your car at the end of the night.  ', 1, 0], ['I liked this movie way too much.  ', 1, 0], [\"Still, I do like this movie for it's empowerment of women; there's not enough movies out there like this one.  \", 1, 0], ['Now you know why I gave it a 10+!  ', 1, 0]]\n",
            "10 Missclassifications of PositiveFalses: \n",
            "[['It was horrendous.  ', 0, 1], [\"The directing and the cinematography aren't quite as good.  \", 0, 1], ['All in all, a great disappointment.  ', 0, 1], ['I saw \"Mirrormask\" last night and it was an unsatisfactory experience.  ', 0, 1], ['The fish is badly made and some of its underwater shots are repeated a thousand times in the film.  ', 0, 1], ['This film has no redeeming features.  ', 0, 1], ['Everything is appalling.  ', 0, 1], ['The kids are annoying.  ', 0, 1], ['The lead man is charisma-free.  ', 0, 1], ['Highly unrecommended.  ', 0, 1]]\n",
            "=========== GNB Missclassification Examples ========\n",
            "Accuracy: 89.08296943231441%\n",
            "10 Missclassifications of FalsePositives: \n",
            "[[\"The movie showed a lot of Florida at it's best, made it look very appealing.  \", 1, 0], ['If there was ever a movie that needed word-of-mouth to promote, this is it.  ', 1, 0], ['It actually turned out to be pretty decent as far as B-list horror/suspense films go.  ', 1, 0], ['Highly entertaining at all angles.  ', 1, 0], ['There is a brilliant twist ending.  ', 1, 0], ['After watching this film, I wanted to learn more about the works of this artist.  ', 1, 0], [\"I like Armand Assante & my cable company's summary sounded interesting, so I watched it, twice already, and probably will again.  \", 1, 0], [\"I won't say any more - I don't like spoilers, so I don't want to be one, but I believe this film is worth your time.  \", 1, 0], ['Easily, none other cartoon made me laugh in a tender way (before getting into dark sitcoms oriented for teenagers).  ', 1, 0], ['Perabo has a nice energy level and is obviously very comfortable in front of a camera.  ', 1, 0]]\n",
            "10 Missclassifications of PositiveFalses: \n",
            "[['There was NOTHING believable about it at all.  ', 0, 1], ['An hour and a half I wish I could bring back.  ', 0, 1], [\"However, this didn't make up for the fact that overall, this was a tremendously boring movie.  \", 0, 1], ['Unfortunately, inexperience of direction meant that scene after scene passed with little in the way of dramatic tension or conflict.  ', 0, 1], ['A truly, truly bad film.  ', 0, 1], ['Again, no plot at all.  ', 0, 1], ['This film has no redeeming features.  ', 0, 1], ['The lead man is charisma-free.  ', 0, 1], ['Nothing at all to recommend.  ', 0, 1], ['There were too many close ups.  ', 0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Model |Parameters| Accuracy\n",
        "---------|----------| --------\n",
        "1| LSTM | 80.59%, Positive Sentiment 81.27%, Negative Sentiment 76.71%\n",
        "2| Multinomial NB, 1-gram            |80.00%\n",
        "3| Multinomial NB, 2-gram            |62.00%\n",
        "4| Multinomial NB, 3-gram            |53.09%\n",
        "5| Multinomial NB                    |92.98%\n",
        "6| Bernoulli NB                      |90.28%\n",
        "7| Gaussian NB                       |89.08%\n"
      ],
      "metadata": {
        "id": "eXEVfUML-UW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding RNN, LSTM\n",
        "\n",
        "RNN is a type of architecture that deals with sequences of data. CNN signals can be one-dimensional, two-dimensional, and three-dimensional depending on the domain. A domain is defined by \"where we mapped it from\" and \"where we mapped it to\" and since a domain is just a temporary input to X, dealing with sequence data is basically the same as dealing with one-dimensional data. Nevertheless, it is possible to handle two-dimensional data with two directions using RNN.\n",
        "\n",
        "The LSTM is explicitly designed to avoid problems with long dependency periods. Remembering long periods of information should be the basic behavior of a model, so that the model doesn't have to spend time to re-learn it every time.\n",
        "\n",
        "The core aspect of LSTM is the cell state, and LSTM has the ability to add or subtract something onto the cell state, which is carefully controlled by the gate composed of sigmoid layers and pointwise multiplication.\n",
        "\n",
        "LSTM First decides what information needs to be thrown out, which is decided by the sigmoid layer. Then, it decides what information needs to be saved. the input gate layer (a sigmoid layer) decides that as well. Then the tanh layer creates a vector to add onto the cell state. Like this, LSTM created a vector to update the state. \n",
        "\n",
        "## Naive Bayes\n",
        "\n",
        "Multinomial Naive Bayes classification is used when the characteristics of the data are expressed by the number of appearances. For example, is a dice rolls 1 once, 2 twice, 3 thrice, the data can be represented as (1,2,3,0,0,0) with each index being the face of the dice, and the value being the number of times they appeared. \n",
        "\n",
        "Bernoulli Naive Bayes is used when the data is expressed as 0s and 1s. Which is what we are using for positive and negative sentiment data. Surprisingly, our results show that Bernouli NB algorithm was in comparison not the best NB model that fits our case. \n",
        "\n",
        "Unlike the two above, Gaussian NB is used when the data is not discrete. is the data is continuous, using GNB can give a better accuracy. This classification is used under the assumption that the values of the features are normally distributed\n",
        "\n",
        "## Comparison and which one I prefer\n",
        "\n",
        "In sentiment analysis, Naive Bayes models were much faster in training and fitting, compared to LSTM. NB models also showed a higher accuracy, and with the understanding of what each classifiers do, we can apply these types of NB models in a lot of scenarios. LSTM is certainly a great way to utilize RNN and use the model to give itself feedback (hence being recurrent). LSTM is a great solution to the vanishing gradient problem, which was originally a problem that LSTM had which older information would have less impact on new weight updates. "
      ],
      "metadata": {
        "id": "poFVQadqOAMk"
      }
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}